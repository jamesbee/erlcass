{"name":"Erlcass","tagline":"An Erlang Cassandra driver, based on Datastax cpp driver focused on performance.","body":"# ErlCass\r\n\r\n*An Erlang Cassandra driver, based on [Datastax cpp driver][3] focused on performance.*\r\n\r\nIn case you want to discuss based on this project join me on [WowApp][2]\r\n\r\n### TODO List:\r\n\r\n- Add support for multiple sessions\r\n- Add support for setting serial consistency,\r\n- Add support for pagination,\r\n- Add support for UDT\r\n- Add support for sending and relieving custom payloads to and from Cassandra\r\n- Add support for server-side warnings\r\n- Add support for retry policies settings\r\n- Add support for client-side timestamps settings\r\n- Add support for Sets/Appends whitelist hosts\r\n- Add support for schema metadata API\r\n\r\n### Changelog:\r\n\r\n##### v2.2\r\n\r\n- Changed the default consistency from `CASS_CONSISTENCY_ONE` to `CASS_CONSISTENCY_LOCAL_QUORUM`\r\n- Updated the cpp-driver to 2.2.0\r\n\r\n##### v2.1\r\n\r\n- Add support for Cassandra 2.2 data types `tinyint` and `smallint`\r\n- Add support for the Cassandra 2.2 `date` and `time` data types\r\n- Add support for functions to convert from Unix Epoch time (in seconds) to and from the Cassandra `date` and `time` types\r\n- Small improvements\r\n- Refactoring the build dependencies script\r\n\r\n##### v2.0\r\n\r\n- Added support for logs from native driver\r\n- Added support for tuples\r\n- Added support for nested collections\r\n- Based on cpp-driver 2.2.0-beta1\r\n- Interfaces changes: `bind_prepared_params` replaced by `bind_prepared_params_by_name` and `bind_prepared_params_by_index`\r\n- Add support for `async_execute/1` and `execute/1` (should be used when no binding params available)\r\n- Add support for `async_execute/3` and `execute/3` (second parameter should be used to specify the binding type - by name or index)\r\n- By default `async_execute/2` and `execute/2` are binding the params by index\r\n\r\n##### v1.0\r\n\r\n- Initial implementation supporting most of the features available in Datastax cpp-driver 1.0.3\r\n\r\n### Getting starting:\r\n\r\n*Usually the rebar script will install for you all dependencies on Cent OS, Ubuntu and Mac OS. So you can skip this section.*\r\n\r\nThis dependecies are required to compile the Datastax c++ driver.\r\nMore details [here][1].\r\n\r\nFor example:\r\n\r\nCentos:\r\n\r\n```sh\r\nsudo yum install automake cmake gcc-c++ git libtool openssl-devel wget\r\npushd /tmp\r\nwget http://libuv.org/dist/v1.7.5/libuv-v1.7.5.tar.gz\r\npushd libuv-v1.7.5\r\ntar xzf libuv-v1.7.5.tar.gz\r\nsh autogen.sh\r\n./configure\r\nsudo make install\r\npopd\r\npopd\r\n```\r\n\r\nAlso on CentOS you need to add `﻿usr/local/lib` into `ldconfig` search path.\r\n\r\n```sh\r\nsu -\r\n﻿nano /etc/ld.so.conf.d/usrlocal.conf\r\n﻿add inside the file: usr/local/lib\r\n﻿ldconfig -v\r\n```\r\n\r\nUbuntu:\r\n\r\n```sh\r\nsudo apt-add-repository ppa:linuxjedi/ppa\r\nsudo apt-get update\r\nsudo apt-get install g++ make cmake libuv-dev libssl-dev\r\n```\r\n\r\nMac OS:\r\n\r\n```sh\r\nbrew install libuv cmake openssl\r\nbrew link --force openssl\r\n```\r\n\r\n### Data types\r\n\r\nHere is a correspondence of Cassandra column types with their equivalent Erlang types\r\n\r\nCassandra Column Type      | Erlang types                                 | Examples\r\n-------------------------- | -------------------------------------------- | :----------------------------:\r\nascii                      | binary or string                             | <<\"hello\">> or \"hello\"\r\nvarchar                    | binary or string                             | <<\"hello\">> or \"hello\"\r\ntext                       | binary or string                             | <<\"hello\">> or \"hello\"\r\nbigint                     | integer (signed 64-bit)                      | 9223372036854775807\r\ntimestamp                  | integer (signed 64-bit)                      | 9223372036854775807\r\ncounter                    | integer (signed 64-bit)                      | 9223372036854775807\r\ntime                       | integer (signed 64-bit)                      | 86399999999999\r\nblob                       | binary                                       | <<1,2,3,4,5,6,7,8,9,10>>\r\nvarint                     | binary                                       | <<\"12423423423423423423243432432\">>\r\nboolean                    | `true`, `false`                              | true\r\ndecimal                    | `{Unscaled :: binary(), Scale :: integer()}` | {<<\"1234\">>, 5}\r\ndouble                     | float (signed 64-bit)                        | 5.1235131241221e-6\r\nfloat                      | float (signed 32-bit)                        | 5.12351e-6\r\ntinyint                    | integer (signed 8-bit)                       | 127\r\nsmallint                   | integer (signed 16-bit)                      | 32767\r\nint                        | integer (signed 32-bit)                      | 2147483647\r\ndate                       | integer (unsigned 32-bit)                    | 2147483648 \t\r\nuuid                       | binary                                       | <<\"61c16fb1-44ca-4591-9317-ac96ddbd8694\">>\r\nvarint                     | binary                                       | <<\"1928301970128391280192830198049113123\">>\r\ntimeuuid                   | binary                                       | <<\"076a46c0-0ad7-11e5-b314-3d7bf89b87a1\">>\r\ninet                       | binary                                       | <<\"127.0.0.1\">>\r\ntuple                      | erlang tuple                                 | {<<\"aaa\">>, 1}\r\n\r\nIn order to generate a uuid v4 you can use `erlcass:uuid_gen_random()` for uuid v1 you can use `erlcass:uuid_gen_time()`.\r\nFor more details please see the section dedicated to uuid's\r\n\r\n### Starting the application\r\n\r\n```erlang\r\napplication:start(erlcass).\r\n```\r\n\r\n### Enable logs and setting custom log handler\r\n\r\nAvailable Log levels are:\r\n\r\n```erlang\r\n-define(CASS_LOG_DISABLED, 0).\r\n-define(CASS_LOG_CRITICAL, 1).\r\n-define(CASS_LOG_ERROR, 2).\r\n-define(CASS_LOG_WARN, 3). (default)\r\n-define(CASS_LOG_INFO, 4).\r\n-define(CASS_LOG_DEBUG,5).\r\n-define(CASS_LOG_TRACE, 6).\r\n```\r\n\r\nIn order to change the log level for the native driver you need to set the `log_level` environment variable for erlcass into your config file.\r\nBy default the logs are printed to console. In order to print them into an external log system you can use the `set_log_function` method.\r\nThe callback should be a function with arity 1 which will receive a record of `log_msg` type defined as\r\n\r\n`\r\n-record(log_msg, {ts, severity, severity_str, file, line, function, message}).\r\n`\r\n\r\nwhere\r\n\r\n- `ts` is The millisecond timestamp (since the Epoch) when the message was logged (int)\r\n- `severity` The severity of the log message (int value from 1 to 6)\r\n- `severity_str` The severity of the log message as a string value (binary string)\r\n- `file` The file where the message was logged (binary string)\r\n- `line` The line in the file where the message was logged (int)\r\n- `function` The function where the message was logged (binary string)\r\n- `message` The message (binary string)\r\n\r\nor under `{_Severity, Msg, Args}` format (for all messages generated from Erlang code)\r\n\r\n### Setting the cluster options\r\n\r\n```erlang\r\nok = erlcass:set_cluster_options([\r\n            {contact_points,<<\"172.17.3.129\">>},\r\n            {load_balance_dc_aware, {<<\"dc-beta\">>, 0, false}},\r\n            {default_consistency_level, ?CASS_CONSISTENCY_ONE},\r\n            {number_threads_io, 4},\r\n            {queue_size_io, 124000},\r\n            {core_connections_host, 5},\r\n            {max_connections_host, 5},\r\n            {tcp_nodelay, true},\r\n            {tcp_keepalive, {true, 60}},\r\n            {pending_requests_high_watermark, 128000}\r\n]).\r\n```\r\n\r\nAvailable options:\r\n\r\n##### contact_points (Mandatory)\r\n\r\nExample : {contact_points, <<\"172.17.3.129\">>}\r\n\r\nSets/Appends contact points. The first call sets the contact points and any subsequent calls appends additional contact points.\r\nPassing an empty string will clear the contact points. White space is striped from the contact points.\r\nAccepted values: <<\"127.0.0.1\">> <<\"127.0.0.1,127.0.0.2\">>, <<\"server1.domain.com\">>\r\n\r\n##### port\r\n\r\nExample: {port, 9042}\r\n\r\nSets the port.\r\n\r\nDefault: 9042\r\n\r\n##### ssl\r\n\r\nExample:\r\n\r\n```erlang\r\n{ssl, [\r\n            {trusted_certs, [<<\"cert1\">>, <<\"cert2\">>]},\r\n            {cert, <<\"cert_here\">>},\r\n            {private_key, {<<\"private_key_here\">>, <<\"private_key_pwd_here\">>}},\r\n            {verify_flags, ?CASS_SSL_VERIFY_PEER_CERT}\r\n        ]\r\n}\r\n```\r\n\r\nSets the SSL context and enables SSL.\r\n\r\nDefault: None\r\n\r\n###### Params:\r\n\r\n```erlang\r\n{ssl, [\r\n        {trusted_certs, CertsList::list()},\r\n        {cert, Cert::binary()},\r\n        {private_key, {PrivateKey::binary(), KeyPassword::binary()}},\r\n        {verify_flags, VerifyFlags::integer()}\r\n       ]\r\n}\r\n```\r\n\r\n- `trusted_certs` : Adds one or more trusted certificate. This is used to verify the peer's certificate.\r\n- `cert` : Set client-side certificate chain. This is used to authenticate the client on the server-side. This should contain the entire Certificate chain starting with the certificate itself.\r\n- `private_key` : Set client-side private key. This is used to authenticate the client on the server-side. PrivateKey is a key PEM formatted key string and KeyPassword is the password used to decrypt key\r\n- `verify_flags` : Sets verification performed on the peer's certificate.\r\n\r\nFor verify_flags use one of the values defined in `erlcass.hrl` :\r\n\r\n```erlang\r\n-define(CASS_SSL_VERIFY_NONE, 0).\r\n-define(CASS_SSL_VERIFY_PEER_CERT, 1).\r\n-define(CASS_SSL_VERIFY_PEER_IDENTITY, 2).\r\n```\r\n\r\n- `CASS_SSL_VERIFY_NONE` - No verification is performed\r\n- `CASS_SSL_VERIFY_PEER_CERT` - Certificate is present and valid\r\n- `CASS_SSL_VERIFY_PEER_IDENTITY` - IP address matches the certificate's common name or one of its subject alternative names. This implies the certificate is also present.\r\n\r\nYou can use also a combination like : `?CASS_SSL_VERIFY_PEER_CERT bor ?CASS_SSL_VERIFY_PEER_IDENTITY`\r\n\r\nDefault: `CASS_SSL_VERIFY_PEER_CERT`\r\n\r\n##### protocol_version\r\n\r\nExample: {protocol_version, 2}\r\n\r\nSets the protocol version. This will automatically downgrade to the lowest protocol version supported.\r\n\r\nDefault: 4\r\n\r\n##### number_threads_io\r\n\r\nExample: {number_threads_io, 1}\r\n\r\nSets the number of IO threads. This is the number of threads that will handle query requests.\r\n\r\nDefault: 1\r\n\r\n##### queue_size_io\r\n\r\nExample: {queue_size_io, 8192}\r\n\r\nSets the size of the the fixed size queue that stores pending requests.\r\n\r\nDefault: 8192\r\n\r\n##### queue_size_event\r\n\r\nExample: {queue_size_event, 8192}\r\n\r\nSets the size of the the fixed size queue that stores events.\r\n\r\nDefault: 8192\r\n\r\n##### core_connections_host\r\n\r\nExample: {core_connections_host, 1}\r\n\r\nSets the number of connections made to each server in each IO thread.\r\n\r\nDefault: 1\r\n\r\n##### max_connections_host\r\n\r\nExample: {max_connections_host, 2}\r\n\r\nSets the maximum number of connections made to each server in each IO thread.\r\n\r\nDefault: 2\r\n\r\n##### reconnect_wait_time\r\n\r\nExample: {reconnect_wait_time, 2000}\r\n\r\nSets the amount of time to wait before attempting to reconnect.\r\n\r\nDefault: 2000 milliseconds\r\n\r\n##### max_concurrent_creation\r\n\r\nExample: {max_concurrent_creation, 1}\r\n\r\nSets the maximum number of connections that will be created concurrently.\r\nConnections are created when the current connections are unable to keep up with request throughput.\r\n\r\nDefault: 1\r\n\r\n##### max_requests_threshold\r\n\r\nExample: {max_requests_threshold, 100}\r\n\r\nSets the threshold for the maximum number of concurrent requests in-flight on a connection before creating a new connection.\r\nThe number of new connections created will not exceed max_connections_host.\r\n\r\nDefault: 100\r\n\r\n##### requests_per_flush\r\n\r\nExample: {requests_per_flush, 128}\r\n\r\nSets the maximum number of requests processed by an IO worker per flush.\r\n\r\nDefault: 128\r\n\r\n##### write_bytes_high_watermark\r\n\r\nExample: {write_bytes_high_watermark, 65536}\r\n\r\nSets the high water mark for the number of bytes outstanding on a connection.\r\nDisables writes to a connection if the number of bytes queued exceed this value.\r\n\r\nDefault: 64 KB\r\n\r\n##### write_bytes_low_watermark\r\n\r\nExample: {write_bytes_low_watermark, 32768}\r\n\r\nSets the low water mark for number of bytes outstanding on a connection.\r\nAfter exceeding high water mark bytes, writes will only resume once the number of bytes fall below this value.\r\n\r\nDefault: 32 KB\r\n\r\n##### pending_requests_high_watermark\r\n\r\nExample: {pending_requests_high_watermark, 256}\r\n\r\nSets the high water mark for the number of requests queued waiting for a connection in a connection pool.\r\nDisables writes to a host on an IO worker if the number of requests queued exceed this value.\r\n\r\nDefault: 256\r\n\r\n\r\n##### pending_requests_low_watermark\r\n\r\nExample: {pending_requests_low_watermark, 128}\r\n\r\nSets the low water mark for the number of requests queued waiting for a connection in a connection pool.\r\nAfter exceeding high water mark requests, writes to a host will only resume once the number of requests fall below this value.\r\n\r\nDefault: 128\r\n\r\n##### connect_timeout\r\n\r\nExample: {connect_timeout, 5000}\r\n\r\nSets the timeout for connecting to a node.\r\n\r\nDefault: 5000 milliseconds\r\n\r\n##### heartbeat_interval\r\n\r\nExample: {heartbeat_interval, 30}\r\n\r\nSets the amount of time between heartbeat messages and controls the amount of time the connection must be idle before sending heartbeat messages.\r\nThis is useful for preventing intermediate network devices from dropping connections.\r\n\r\nDefault: 30 seconds\r\n\r\n##### idle_timeout\r\n\r\nExample: {idle_timeout, 60}\r\n\r\nSets the amount of time a connection is allowed to be without a successful heartbeat response before being terminated and scheduled for reconnection.\r\n\r\nDefault: 60 seconds\r\n\r\n##### request_timeout\r\n\r\nExample: {request_timeout, 12000}\r\n\r\nSets the timeout for waiting for a response from a node.\r\n\r\nDefault: 12000 milliseconds\r\n\r\n##### credentials\r\n\r\nExample: {credentials, {<<\"username\">>, <<\"password\">>}}\r\n\r\nSets credentials for plain text authentication.\r\n\r\n##### load_balance_round_robin\r\n\r\nExample: {load_balance_round_robin, true}\r\n\r\nConfigures the cluster to use round-robin load balancing.\r\nThe driver discovers all nodes in a cluster and cycles through them per request. All are considered 'local'.\r\n\r\n##### load_balance_dc_aware\r\n\r\nExample: {load_balance_dc_aware, {\"dc_name\", 2, true}}\r\n\r\nConfigures the cluster to use DC-aware load balancing.\r\nFor each query, all live nodes in a primary 'local' DC are tried first, followed by any node from other DCs.\r\n\r\n###### Note:\r\n\r\nThis is the default, and does not need to be called unless switching an existing from another policy or changing settings.\r\nWithout further configuration, a default local_dc is chosen from the first connected contact point, and no remote hosts are considered in query plans.\r\nIf relying on this mechanism, be sure to use only contact points from the local DC.\r\n\r\n###### Params:\r\n\r\n*{load_balance_dc_aware, {LocalDc, UsedHostsPerRemoteDc, AllowRemoteDcsForLocalCl}}*\r\n\r\n* LocalDc - The primary data center to try first\r\n* UsedHostsPerRemoteDc - The number of host used in each remote DC if no hosts are available in the local dc\r\n* AllowRemoteDcsForLocalCl - Allows remote hosts to be used if no local dc hosts are available and the consistency level is LOCAL_ONE or LOCAL_QUORUM\r\n\r\n##### token_aware_routing\r\n\r\nExample: {token_aware_routing, true}\r\n\r\nConfigures the cluster to use token-aware request routing, or not.\r\nThis routing policy composes the base routing policy, routing requests first to replicas on nodes considered 'local' by the base load balancing policy.\r\n\r\nDefault is true (enabled).\r\n\r\n#### latency_aware_routing\r\n\r\nExample:\r\n\r\n- `{latency_aware_routing, true}`\r\n- `{latency_aware_routing, {true, {2.0, 100, 10000, 100 , 50}}}`\r\n\r\nConfigures the cluster to use latency-aware request routing, or not.\r\nThis routing policy is a top-level routing policy.\r\nIt uses the base routing policy to determine locality (dc-aware) and/or placement (token-aware) before considering the latency.\r\n\r\n###### Params:\r\n\r\n{Enabled, {ExclusionThreshold, ScaleMs, RetryPeriodMs, UpdateRateMs, MinMeasured}}\r\n\r\n- Enabled : State of the future\r\n- ExclusionThreshold : Controls how much worse the latency must be compared to the average latency of the best performing node before it penalized.\r\n- ScaleMs Controls the weight given to older latencies when calculating the average latency of a node. A bigger scale will give more weight to older latency measurements.\r\n- RetryPeriodMs -  The amount of time a node is penalized by the policy before being given a second chance when the current average latency exceeds the calculated threshold (ExclusionThreshold * BestAverageLatency).\r\n- UpdateRateMs - The rate at  which the best average latency is recomputed.\r\n- MinMeasured - The minimum number of measurements per-host required to be considered by the policy.\r\n\r\nDefaults: {false, {2.0, 100, 10000, 100 , 50}}\r\n\r\n###### Note: In case you use only true false atom the tuning settings will not change.\r\n\r\n##### tcp_nodelay\r\n\r\nExample: {tcp_nodelay, false}\r\n\r\nEnable/Disable Nagel's algorithm on connections.\r\n\r\nDefault: true (disabled).\r\n\r\n##### tcp_keepalive\r\n\r\nExample: {tcp_keepalive, {true, 60}}\r\n\r\nEnable/Disable TCP keep-alive\r\n\r\nDefault: cass_false (disabled).\r\n\r\n##### default_consistency_level\r\n\r\nExample: {default_consistency_level, ?CASS_CONSISTENCY_LOCAL_QUORUM}\r\n\r\nSet the default consistency level\r\n\r\nDefault: ?CASS_CONSISTENCY_LOCAL_QUORUM\r\n\r\n### Creating a session\r\n\r\n*Currently this is limited to one session per application. This is a Datastax recommendations as well*\r\n\r\nIn order to connect the session to a keyspace as well use as option:\r\n\r\n```erlang\r\n [{keyspace, <<\"keyspace_name_here\">>}].\r\n```\r\nIn case you don't want to connect the session to any keyspace use as argument an empty list.\r\n\r\nExample:\r\n\r\n```erlang\r\nok = erlcass:create_session([{keyspace, <<\"stresscql\">>}]).\r\n```\r\n\r\n### Add a prepare statement\r\n\r\nExample:\r\n\r\n```erlang\r\nok = erlcass:add_prepare_statement(select_blogpost,\r\n                                   <<\"select * from blogposts where domain = ? LIMIT 1\">>),\r\n```\r\n\r\nIn case you want to overwrite the default consistency level for that prepare statement use a tuple for the query argument: *{Query, ConsistencyLevelHere}*\r\n\r\nExample:\r\n\r\n```erlang\r\nok = erlcass:add_prepare_statement(\r\n                select_blogpost,\r\n                { <<\"select * from blogposts where domain = ? LIMIT 1\">>, ?CASS_CONSISTENCY_LOCAL_QUORUM }).\r\n```\r\n\r\n### Run a prepared statement query\r\n\r\nIn case the first parameter for *erlcass:execute* is an atom then the driver will try to find the associated prepared statement and to run it.\r\nYou can bind the parameters in 2 ways: by name and by index. You can use `?BIND_BY_INDEX` and `?BIND_BY_NAME` from execute/3 in order to specify the desired method. By default is binding by index\r\n\r\nExample:\r\n\r\n```erlang\r\n%bind by name\r\nerlcass:execute(select_blogpost, ?BIND_BY_NAME, [{<<\"domain\">>, <<\"Domain_1\">>}]).\r\n%bind by index\r\nerlcass:execute(select_blogpost, [<<\"Domain_1\">>]).\r\n%bind by index\r\nerlcass:execute(select_blogpost, ?BIND_BY_INDEX, [<<\"Domain_1\">>]).\r\n```\r\n\r\nIn case of maps you can use `key(field)` and `value(field)` in order to bind by name.\r\n\r\n```erlang\r\n%table: CREATE TABLE test_map(key int PRIMARY KEY, value map<text,text>)\r\n%statement: UPDATE examples.test_map SET value[?] = ? WHERE key = ?\r\n%bind by index\r\nerlcass:execute(identifier, [<<\"collection_key_here\">>, <<\"collection_value_here\">>, <<\"key_here\">>]).\r\n%bind by name\r\nerlcass:execute(insert_test_bind, ?BIND_BY_NAME, [{<<\"key(value)\">>, CollectionIndex1}, {<<\"value(value)\">>, CollectionValue1}, {<<\"key\">>, Key1}]),\r\n```\r\n\r\n### Async queries and blocking queries\r\n\r\nFor blocking operations use *erlcass:execute*, for async execution use : *erlcass:async_execute*.\r\nThe blocking operation will block the current erlang process (still async into the native code in order to avoid freezing of the VM threads) until will get the result from the cluster.\r\n\r\nIn case of an async execution the calling process will receive a message of the following form: *{execute_statement_result, Tag, Result}*\r\n\r\nFor example:\r\n\r\n```erlang\r\n{ok, Tag} = erlcass:async_execute(...),\r\n    receive\r\n        {execute_statement_result, Tag, Result} ->\r\n            Result\r\n    end.\r\n```\r\n\r\n### Non prepared statements queries\r\n\r\nThe only downside is that you have to provide metadata about the types of the fields that are bound.\r\nThe datatypes can be found into *erlcass.hrl* file as follow:\r\n\r\n```erlang\r\n-define(CASS_TEXT, text).                         %use for (ascii, text, varchar)\r\n-define(CASS_TINYINT, tinyint).                   %use for (tinyint)\r\n-define(CASS_SMALLINT, smallint).                 %use for (smallint)\r\n-define(CASS_INT, int).                           %use for (int)\r\n-define(CASS_DATE, date).                         %use for (date)\r\n-define(CASS_BIGINT, bigint).                     %use for (timestamp, counter, bigint, time)\r\n-define(CASS_BLOB, blob).                         %use for (varint, blob)\r\n-define(CASS_BOOLEAN, bool).                      %use for (bool)\r\n-define(CASS_FLOAT, float).                       %use for (float)\r\n-define(CASS_DOUBLE, double).                     %use for (double)\r\n-define(CASS_INET, inet).                         %use for (inet)\r\n-define(CASS_UUID, uuid).                         %use for (timeuuid, uuid)\r\n-define(CASS_DECIMAL, decimal).                   %use for (decimal)\r\n-define(CASS_LIST(ValueType), {list, ValueType}). %use for list\r\n-define(CASS_SET(ValueType), {set, ValueType}).   %use for set\r\n-define(CASS_MAP(KeyType, ValueType), {map, KeyType, ValueType}). %use for map\r\n-define(CASS_TUPLE(Types), {tuple, Types}).       %use for tuples\r\n```\r\n\r\nThe same rules apply for setting the desired consistency level as on prepared statements (see Add prepare statement section).\r\nExample with binding by index (requires metadata parsing all the time so it might not be the best solution when using non prepared statements):\r\n\r\n```erlang\r\nerlcass:execute(<<\"select * from blogposts where domain = ? LIMIT 1\">>,\r\n                [{?CASS_TEXT, <<\"Domain_1\">>}]).\r\n```\r\nor:\r\n\r\n```erlang\r\nerlcass:execute(<<\"select * from blogposts where domain = 'Domain_1' LIMIT 1\">>).\r\n```\r\n\r\n### Batched queries\r\n\r\nIn order to perform batched statements you can use `erlcass:batch_async_execute/3` or `erlcass:batch_execute/3`.\r\n\r\nFirst argument is the batch type and is defined as:\r\n\r\n```erlang\r\n-define(CASS_BATCH_TYPE_LOGGED, 0).\r\n-define(CASS_BATCH_TYPE_UNLOGGED, 1).\r\n-define(CASS_BATCH_TYPE_COUNTER, 2).\r\n```\r\n\r\nThe second one is a list of statements (prepared or normal statements) that needs to be executed in the batch.\r\n\r\nThe third argument is a list of options currently ony `consistency_level` is available. If it's missing the batch will be\r\nexecuted using the default consistency level value.\r\n\r\nExample:\r\n\r\n```erlang\r\nInsertStatement = <<\"INSERT INTO erlang_driver_test.entries1(id, age, email) VALUES (?, ?, ?)\">>,\r\nok = erlcass:add_prepare_statement(insert_prep, InsertStatement),\r\n{ok, Stm1} = erlcass:create_statement(InsertStatement, [{?CASS_TEXT, Id1}, {?CASS_INT, Age1}, {?CASS_TEXT, Email1}]),\r\n{ok, Stm2} = erlcass:bind_prepared_statement(insert_prep),\r\nok = erlcass:bind_prepared_params_by_name(Stm2, [{<<\"id\">>, Id2}, {<<\"age\">>, Age2}, {<<\"email\">>, Email2}]),\r\n{ok, []} = erlcass:batch_execute(?CASS_BATCH_TYPE_LOGGED, [Stm1, Stm2], [{consistency_level, ?CASS_CONSISTENCY_QUORUM}]).\r\n```\r\n\r\n### Working with uuid or timeuuid fields:\r\n\r\n- `erlcass:uuid_gen_time()`   -> Generates a V1 (time) UUID\r\n- `erlcass:uuid_gen_random()` -> Generates a new V4 (random) UUID\r\n- `erlcass:uuid_gen_from_ts(Ts)` -> Generates a V1 (time) UUID for the specified timestamp\r\n- `erlcass:uuid_min_from_ts(Ts)` -> Sets the UUID to the minimum V1 (time) value for the specified timestamp,\r\n- `erlcass:uuid_max_from_ts(Ts)` -> Sets the UUID to the maximum V1 (time) value for the specified timestamp,\r\n- `erlcass:uuid_get_ts(Uuid)` -> Gets the timestamp for a V1 UUID,\r\n- `erlcass:uuid_get_version(Uuid)` -> Gets the version for a UUID (V1 or V4)\r\n\r\n### Working with date, time fields:\r\n\r\n- `erlcass:date_from_epoch(EpochSecs)` -> Converts a unix timestamp (in seconds) to the Cassandra `date` type. The `date` type represents the number of days since the Epoch (1970-01-01) with the Epoch centered at the value 2^31.\r\n- `erlcass:time_from_epoch(EpochSecs)` -> Converts a unix timestamp (in seconds) to the Cassandra `time` type. The `time` type represents the number of nanoseconds since midnight (range 0 to 86399999999999).\r\n- `erlcass:date_time_to_epoch(Date, Time)` -> Combines the Cassandra `date` and `time` types to Epoch time in seconds. Returns Epoch time in seconds. Negative times are possible if the date occurs before the Epoch (1970-1-1).\r\n\r\n### Getting metrics\r\n\r\nIn order to get metrics from the native driver you can use `erlcass:get_metrics().`\r\n\r\n##### requests\r\n\r\n- `min` - Minimum in microseconds\r\n- `max` - Maximum in microseconds\r\n- `mean` - Mean in microseconds\r\n- `stddev` - Standard deviation in microseconds\r\n- `median` - Median in microseconds\r\n- `percentile_75th` - 75th percentile in microseconds\r\n- `percentile_95th` - 95th percentile in microseconds\r\n- `percentile_98th` - 98th percentile in microseconds\r\n- `percentile_99th` - 99the percentile in microseconds\r\n- `percentile_999th` - 99.9th percentile in microseconds\r\n- `mean_rate` - Mean rate in requests per second\r\n- `one_minute_rate` - 1 minute rate in requests per second\r\n- `five_minute_rate` - 5 minute rate in requests per second\r\n- `fifteen_minute_rate` - 15 minute rate in requests per second\r\n\r\n##### stats\r\n\r\n- `total_connections` - The total number of connections\r\n- `available_connections` - The number of connections available to take requests\r\n- `exceeded_pending_requests_water_mark` - Occurrences when requests exceeded a pool's water mark\r\n- `exceeded_write_bytes_water_mark` - Occurrences when number of bytes exceeded a connection's water mark\r\n\r\n##### errors\r\n\r\n- `connection_timeouts` - Occurrences of a connection timeout\r\n- `pending_request_timeouts` - Occurrences of requests that timed out waiting for a connection\r\n- `request_timeouts` - Occurrences of requests that timed out waiting for a request to finish\r\n\r\n### Low level methods\r\n\r\nEach query requires an internal statement (prepared or not). You can reuse the same statement object for multiple queries\r\nperformed in the same process.\r\n\r\n##### Getting a statement reference for a prepared statement query\r\n\r\n```erlang\r\n{ok, Statement} = erlcass:bind_prepared_statement(select_blogpost).\r\n```\r\n\r\n##### Getting a statement reference for a non prepared query\r\n\r\n```erlang\r\n{ok, Statement} = erlcass:create_statement(<<\"select * from blogposts where domain = ? LIMIT 1\">>,\r\n                                           [{?CASS_TEXT, <<\"Domain_1\">>}]).\r\n```\r\n\r\n##### Bind the values for a prepared statement before executing\r\n\r\n```erlang\r\n%bind by name\r\nok = erlcass:bind_prepared_params_by_name(select_blogpost, [{<<\"domain\">>, <<\"Domain_1\">>}]);\r\n%bind by index\r\nok = erlcass:bind_prepared_params_by_index(select_blogpost, [<<\"Domain_1\">>]);\r\n```\r\n\r\nFor mode details about bind by index and name please see: 'Run a prepared statement query' section\r\n\r\n##### Execute a statement async\r\n\r\n```erlang\r\n{ok, Tag} = erlcass:async_execute_statement(Statement).\r\n```\r\n\r\n##### Execute a statement in blocking mode\r\n\r\n```erlang\r\nResult = erlcass:execute_statement(Statement).\r\n```\r\n\r\nUsing this low level functions are very useful when you want to run in loop a certain query. Helps you to avoid recreating the statements all the time.\r\nFor example here is how the execute method is implemented:\r\n\r\n```erlang\r\nexecute(Identifier, Params) ->\r\n    if\r\n        is_atom(Identifier) ->\r\n            {ok, Statement} = bind_prepared_statement(Identifier),\r\n            ok = bind_prepared_params(Statement, Params);\r\n        true ->\r\n            {ok, Statement} = create_statement(Identifier, Params)\r\n    end,\r\n    execute_statement(Statement).\r\n```\r\n\r\n[1]:http://datastax.github.io/cpp-driver/topics/building/\r\n[2]:https://www.wowapp.com/w/silviu/Silviu-Caragea\r\n[3]:https://github.com/datastax/cpp-driver\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}